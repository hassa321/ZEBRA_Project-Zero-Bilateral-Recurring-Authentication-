{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "csc490.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlqVX3TfbWQI",
        "colab_type": "text"
      },
      "source": [
        "# CSC490H5 Model.\n",
        "\n",
        "---\n",
        "\n",
        "I am trying to make the model that the researchers used in this paper: https://arxiv.org/pdf/1505.05779.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5eNkWvhbWQQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import re\n",
        "import glob\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN0FBezuFO4K",
        "colab_type": "text"
      },
      "source": [
        "Connect to google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DJIRx-YbWQd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d08175e-ed6d-4db4-d70d-3f68b37a44b8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDPwmxxsbWQk",
        "colab_type": "code",
        "outputId": "acc9f81d-0651-4629-a928-6fbd1539a272",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "path_to_data = \"/content/gdrive/My Drive/School Winter 2020/Csc490/data/\"\n",
        "\n",
        "watch_data = path_to_data + '*.csv'\n",
        "keyboard_log = path_to_data + '*.log'\n",
        "\n",
        "watch_acceleration = {}\n",
        "keyboard_logs = {}\n",
        "\n",
        "for file in glob.glob(watch_data):\n",
        "  # So using glob messes with order, which is why we are doing this\n",
        "  filename = int(file.split(\"/\")[-1].strip(\".csv\").strip(\"watch_\"))-1\n",
        "  wa = [line.strip().split(\",\") for line in open(file) if line.strip().split(\",\") != '']\n",
        "  watch_acceleration[filename] = wa\n",
        "\n",
        "for file in glob.glob(keyboard_log):\n",
        "  filename = int(file.split(\"/\")[-1].strip(\".log\").strip(\"keys_\"))-1\n",
        "  kd = [line.strip() for line in open(file)]\n",
        "  keyboard_logs[filename] = kd\n",
        "\n",
        "\n",
        "# This is to fix the mess caused by glob\n",
        "watch_acc = []\n",
        "for i in range(len(watch_acceleration.keys())):\n",
        "  watch_acc.extend(watch_acceleration[i])\n",
        "\n",
        "print(len(watch_acc))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "190241\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcxfXRLPGGwk",
        "colab_type": "text"
      },
      "source": [
        "Seperate the keyboard log into \"key pressed\" and \"key up\" events."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AVkjX4xGVIc",
        "colab_type": "code",
        "outputId": "054c05d9-c108-4f8c-9c5a-54a3be4cd0b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "locations = {\"left\": 0, \"center\": 1, \"right\": 2}\n",
        "special_keys = {\"Shift\": 1, \"Control\": 2, \"Alt\": 3, \"None\": 0}\n",
        "\n",
        "all_keys_pressed = {}\n",
        "all_keys_released = {}\n",
        "all_keys_used = [] # Used later in one_hotting the keys\n",
        "last_event = None\n",
        "\n",
        "p = re.compile(r\"index.html:[0-9]* (?P<timestamp>[0-9]*), (?P<event>[a-z]*), (?P<key>([a-zA-Z0-9]*|[^a-zA-Z0-9_])), (?P<location>(left|center|right))\")\n",
        "\n",
        "for index in keyboard_logs.keys():\n",
        "  key_log = keyboard_logs[index]\n",
        "  keys_pressed = []\n",
        "  keys_released = []\n",
        "  for line in key_log:\n",
        "    s = p.search(line)\n",
        "\n",
        "    timestamp = int(s.group(\"timestamp\"))\n",
        "    event     = s.group(\"event\")\n",
        "    key       = s.group(\"key\")\n",
        "    location  = s.group(\"location\")\n",
        "\n",
        "    # If the special keys were pressed with the others, then just add as a tag\n",
        "    if key in [\"Shift\", \"Control\", \"Alt\"] and last_event == \"keypress\":\n",
        "      keys_pressed[-1][-1] = special_keys[key]\n",
        "      continue \n",
        "\n",
        "    last_event = event\n",
        "\n",
        "    if event == \"keypress\":\n",
        "      # Timestamp, key side, key\n",
        "      keys_pressed.append([timestamp, key, locations[location], 0]) # Last is for special keys\n",
        "    elif event == \"keyup\" and key not in [\"Shift\", \"Control\", \"Alt\", \"Backspace\", \"ArrowLeft\", \"ArrowRight\"]:\n",
        "      # For now ignore these, figuring out what to do with them is a later problem\n",
        "      keys_released.append([timestamp, key, locations[location], 0])\n",
        "  all_keys_pressed[index] = keys_pressed\n",
        "  all_keys_released[index] = keys_released\n",
        "\n",
        "# We would like to start measuring from when our first key is let go \n",
        "# Because that is how we measure sequences\n",
        "\n",
        "keys_pressed = []\n",
        "keys_released = []\n",
        "\n",
        "for index in all_keys_pressed.keys():\n",
        "  kp = all_keys_pressed[index]\n",
        "  keys_pressed.extend(kp[1:])\n",
        "\n",
        "for index in all_keys_released.keys():\n",
        "  kr = all_keys_released[index]\n",
        "  keys_released.extend(kr[0:-1])\n",
        "\n",
        "print(len(keys_pressed))    # 10473\n",
        "print(len(keys_released))   # 10473"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10473\n",
            "10473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNSJCRNpFarQ",
        "colab_type": "text"
      },
      "source": [
        "Go through all our data and split up the watch data by the timestamp from the keyboard log. \n",
        "\n",
        "Each sequence begins when the first key is lifted, and ends when the next key is pressed. \n",
        "\n",
        "Map each sequence to a key."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyW1D_IJbWQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = []\n",
        "predictions = []\n",
        "predictions_loc = []\n",
        "count = 0\n",
        "\n",
        "copy_acc = watch_acc\n",
        "\n",
        "for i in range(len(keys_pressed)):\n",
        "\n",
        "  if count > 10:\n",
        "    break \n",
        "  start = int(keys_released[i][0])\n",
        "  end = int(keys_pressed[i][0])\n",
        "\n",
        "  key = keys_pressed[i][1]\n",
        "  loc = keys_pressed[i][2] #Ignore for now\n",
        "\n",
        "  sequence = []\n",
        "\n",
        "  while len(copy_acc) != 0:\n",
        "    # We want to remove the line so we dont have to iterate trough everything again\n",
        "    line = copy_acc.pop(0)\n",
        "    if line == ['']:\n",
        "      continue \n",
        "\n",
        "    time, acc_x, acc_y, acc_z = line[0], line[1], line[2], line[3]\n",
        "\n",
        "    current_time = int(time)\n",
        "\n",
        "    if current_time < start:\n",
        "      continue \n",
        "    if current_time >= end:\n",
        "      break \n",
        "\n",
        "    sequence.append([float(acc_x), float(acc_y), float(acc_z)])\n",
        "  predictions.append(key)\n",
        "  predictions_loc.append(loc)\n",
        "  sequences.append(sequence)\n",
        "\n",
        "# We want to know how much data we have\n",
        "# Should match up with how many keys_pressed we have\n",
        "print(len(sequences))\n",
        "print(len(predictions)) \n",
        "print(sequences[:5])\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nXBa3GHpJig",
        "colab_type": "text"
      },
      "source": [
        "Now we pad the shorter sequences with [0, 0, 0] to match the length of the longest sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emIM0-N4pQh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(max(sequences,key=len))\n",
        "max_len = len(max(sequences,key=len))\n",
        "print(max_len)\n",
        "\n",
        "padded_sequences = []\n",
        "for sequence in sequences:\n",
        "  while len(sequence) < max_len:\n",
        "     sequence.append([0, 0, 0])\n",
        "  np.stack(sequence)\n",
        "  padded_sequences.append(sequence)\n",
        "np_sequences = np.stack(padded_sequences)\n",
        "\n",
        "print(np_sequences.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogCwlcxjsLKP",
        "colab_type": "text"
      },
      "source": [
        "Now we make our classifier\n",
        "\n",
        "It should take in a vector thats **N * M * 3**\n",
        "\n",
        "Where N = Number of squences and M = Sequence length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcDOAth0sS1_",
        "colab_type": "code",
        "outputId": "47180b7e-8026-4a5b-bcef-d69caa93dac6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Our shape is (10473, 256, 3)\n",
        "\n",
        "# Ok weird the shape changed to (10473, 220, 3)\n",
        "\n",
        "# So sklearn expects 2d arrays... gotta reshape\n",
        "N, nx, ny = np_sequences.shape\n",
        "new_sequences = np_sequences.reshape((N,nx*ny))\n",
        "\n",
        "# Split into train, validation, and test sets\n",
        "# I will do about 70 train and 30 test\n",
        "train_data, test_data = new_sequences[:7730,:], new_sequences[7730:,:]\n",
        "print (train_data.shape)\n",
        "print (test_data.shape)\n",
        "train_ts, test_ts = predictions[:7730], predictions[7730:]\n",
        "\n",
        "#Create a Gaussian Classifier\n",
        "rfc=RandomForestClassifier(n_estimators=150, max_features=0.15, min_samples_leaf=60, oob_score=True)\n",
        "\n",
        "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
        "rfc.fit(train_data,train_ts)\n",
        "\n",
        "test_ys=rfc.predict(test_data)\n",
        "\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(test_ts, test_ys))\n",
        "# Key Prediction = 19% accuracy\n",
        "# Location Pred = 54.5 - 54.8%"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7730, 660)\n",
            "(2743, 660)\n",
            "Accuracy: 0.19248997448049582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1hb0T-uOY14",
        "colab_type": "text"
      },
      "source": [
        "Ok let's try a different model - rnn sequential\n",
        "\n",
        "First we will have to convert the predictions into their numerical form"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WEB6ZoxOYDC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "eff8082b-9ae3-438e-fe13-0f7f08c7a675"
      },
      "source": [
        "uniq_pred = np.unique(predictions_loc)\n",
        "num_uniq = uniq_pred.shape[0]\n",
        "\n",
        "pred_numbered = []\n",
        "for key in predictions_loc:\n",
        "  pred_numbered.append(list(uniq_pred).index(key))\n",
        "\n",
        "uniq_pred2 = np.unique(pred_numbered)\n",
        "num_uniq2 = uniq_pred2.shape[0]\n",
        "\n",
        "print(uniq_pred, num_uniq)\n",
        "print(uniq_pred2, num_uniq2)\n",
        "\n",
        "def make_onehot(indicies, total=250):\n",
        "    \"\"\"\n",
        "    Convert indicies into one-hot vectors by\n",
        "        1. Creating an identity matrix of shape [total, total]\n",
        "        2. Indexing the appropriate columns of that identity matrix\n",
        "    \"\"\"\n",
        "    I = np.eye(total)\n",
        "    return I[indicies]\n",
        "\n",
        "hot_predictions = make_onehot(pred_numbered, num_uniq2)\n",
        "print (hot_predictions[:5])"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2] 3\n",
            "[0 1 2] 3\n",
            "[[0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi7x8OwebWQ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "14621ad3-abf5-44db-8050-5419fdca32ac"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Split into train, validation, and test sets\n",
        "# I will do about 76 train, 20 valid and 20 test\n",
        "\n",
        "N, nx, ny = np_sequences.shape\n",
        "new_sequences = np_sequences.reshape((N,nx*ny))\n",
        "\n",
        "train_data, valid_data, test_data = new_sequences[:6283,:],  new_sequences[6283:8378,:], new_sequences[8378:,:]\n",
        "print (train_data.shape)\n",
        "print (valid_data.shape)\n",
        "print (test_data.shape)\n",
        "train_ts, valid_ts, test_ts = hot_predictions[:6283],  hot_predictions[6283:8378], hot_predictions[8378:]\n",
        "\n",
        "dim = nx*ny\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(N, activation='relu', input_dim=dim))  # returns a sequence of vectors of dimension 32\n",
        "#model.add(Dense(N, activation='relu'))  # returns a sequence of vectors of dimension 32\n",
        "model.add(Dense(3, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_data, train_ts,\n",
        "          batch_size=64, epochs=10,\n",
        "          validation_data=(valid_data, valid_ts))\n",
        "\n",
        "\n",
        "score = model.evaluate(test_data, test_ts, batch_size=64)\n",
        "print(score)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6283, 660)\n",
            "(2095, 660)\n",
            "(2095, 660)\n",
            "Train on 6283 samples, validate on 2095 samples\n",
            "Epoch 1/10\n",
            "6283/6283 [==============================] - 14s 2ms/step - loss: 1.0170 - acc: 0.5197 - val_loss: 1.0082 - val_acc: 0.5317\n",
            "Epoch 2/10\n",
            "6283/6283 [==============================] - 13s 2ms/step - loss: 1.0020 - acc: 0.5376 - val_loss: 1.0091 - val_acc: 0.5317\n",
            "Epoch 3/10\n",
            "6283/6283 [==============================] - 13s 2ms/step - loss: 0.9921 - acc: 0.5421 - val_loss: 1.0105 - val_acc: 0.5317\n",
            "Epoch 4/10\n",
            "6283/6283 [==============================] - 13s 2ms/step - loss: 0.9876 - acc: 0.5437 - val_loss: 1.0127 - val_acc: 0.5317\n",
            "Epoch 5/10\n",
            "6283/6283 [==============================] - 13s 2ms/step - loss: 0.9809 - acc: 0.5472 - val_loss: 1.0085 - val_acc: 0.5317\n",
            "Epoch 6/10\n",
            "6283/6283 [==============================] - 13s 2ms/step - loss: 0.9754 - acc: 0.5488 - val_loss: 1.0083 - val_acc: 0.5317\n",
            "Epoch 7/10\n",
            "6283/6283 [==============================] - 13s 2ms/step - loss: 0.9692 - acc: 0.5537 - val_loss: 1.0101 - val_acc: 0.5317\n",
            "Epoch 8/10\n",
            "6283/6283 [==============================] - 13s 2ms/step - loss: 0.9666 - acc: 0.5556 - val_loss: 1.0096 - val_acc: 0.5317\n",
            "Epoch 9/10\n",
            "6283/6283 [==============================] - 13s 2ms/step - loss: 0.9628 - acc: 0.5566 - val_loss: 1.0084 - val_acc: 0.5317\n",
            "Epoch 10/10\n",
            "6283/6283 [==============================] - 13s 2ms/step - loss: 0.9573 - acc: 0.5587 - val_loss: 1.0134 - val_acc: 0.5317\n",
            "2095/2095 [==============================] - 1s 341us/step\n",
            "[1.0567520599945632, 0.5632458229053561]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}