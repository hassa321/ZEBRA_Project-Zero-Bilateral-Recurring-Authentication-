{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlqVX3TfbWQI",
        "colab_type": "text"
      },
      "source": [
        "# CSC490H5 Model.\n",
        "\n",
        "---\n",
        "\n",
        "This is the \"backend\" of our Random Forest Classifier Model. \n",
        "Here the watch and keyboard data is processed, and our model is then trained on that data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5eNkWvhbWQQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.14\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import re\n",
        "import glob\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN0FBezuFO4K",
        "colab_type": "text"
      },
      "source": [
        "Connect to google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DJIRx-YbWQd",
        "colab_type": "code",
        "outputId": "ff9bc269-92dc-4a72-eea7-fba3fc0084a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDPwmxxsbWQk",
        "colab_type": "code",
        "outputId": "dc7bc3b9-8e80-43b8-c2ae-2ca3d553b983",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "path_to_keys = \"/content/gdrive/My Drive/School Winter 2020/Csc490/data/v2/keys/\"\n",
        "path_to_watch = \"/content/gdrive/My Drive/School Winter 2020/Csc490/data/v2/watch/\"\n",
        "\n",
        "watch_data = path_to_watch + '*.csv'\n",
        "keyboard_log = path_to_keys + '*.log'\n",
        "\n",
        "watch_acceleration = {}\n",
        "keyboard_logs = {}\n",
        "\n",
        "for file in glob.glob(watch_data):\n",
        "  filename = file.split(\"/\")[-1].strip(\".csv\").strip(\"watch_\")\n",
        "  wa = [line.strip().split(\",\") for line in open(file) if line.strip().split(\",\") != '']\n",
        "  watch_acc = wa\n",
        "\n",
        "for file in glob.glob(keyboard_log):\n",
        "  filename = int(file.split(\"/\")[-1].strip(\".log\").strip(\"keys_\"))-1\n",
        "  kd = [line.strip() for line in open(file)]\n",
        "  keyboard_logs[filename] = kd\n",
        "\n",
        "print(len(watch_acc))"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "127914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcxfXRLPGGwk",
        "colab_type": "text"
      },
      "source": [
        "Seperate the keyboard log into \"key pressed\" and \"key up\" events."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AVkjX4xGVIc",
        "colab_type": "code",
        "outputId": "087b13dd-aed4-43d8-c365-d20e928e3d31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "locations = {\"left\": 0, \"center\": 1, \"right\": 2}\n",
        "special_keys = {\"shift\": 1, \"control\": 2, \"alt\": 3, \"None\": 0}\n",
        "\n",
        "# Big Boi List\n",
        "keys_mapped = {'1': 1, '2': 1, '3': 1, '!': 1, '@': 1, '#': 1, '4': 2, '5': 2, \n",
        "               '6': 2, '$': 2, '%': 2, '^': 2, '7': 3, '8': 3, '&': 3, '*': 3, \n",
        "               '9': 4, '0': 4, '(': 4, ')': 4, '-': 5, '_': 5, '=': 5, '+': 5, \n",
        "               'backspace': 5, 'q': 6, 'tab': 6, 'w': 7, 'e': 7, 'r': 7, 't': 8, \n",
        "               'y': 8, 'u': 9, 'i': 9, 'o': 9, 'p': 9, '[': 10, ']': 10, \n",
        "               '\\\\': 10, '{': 10, '}': 10, '|': 10, 'a': 11, 's': 11, 'd': 11, \n",
        "               'f': 12, 'g': 12, 'h': 12, 'j': 13, 'k': 13, 'l': 13, ';': 14, \n",
        "               \"'\": 14, '\"': 14, ':': 14, 'enter': 14, 'z': 15, 'x': 15, 'c': 15, \n",
        "               'space': 16, 'b': 16, 'n': 16, 'm': 16, ',': 17, '.': 17, '/': 17, \n",
        "               '<': 17, '>': 17, '?': 17, 'arrowleft': 18, 'arrowright': 18, \n",
        "               'arrowup': 18, 'arrowdown': 18}\n",
        "\n",
        "all_keys_pressed = {}\n",
        "all_keys_released = {}\n",
        "last_event = None\n",
        "\n",
        "p = re.compile(r\"index.html:[0-9]* (?P<timestamp>[0-9]*), (?P<event>[a-z]*), (?P<key>([a-zA-Z0-9]*|[^a-zA-Z0-9_])), (?P<location>(left|center|right))\")\n",
        "\n",
        "for index in keyboard_logs.keys():\n",
        "  key_log = keyboard_logs[index]\n",
        "  keys_pressed = []\n",
        "  keys_released = []\n",
        "  for line in key_log:\n",
        "    s = p.search(line)\n",
        "\n",
        "    timestamp = int(s.group(\"timestamp\"))\n",
        "    event     = s.group(\"event\")\n",
        "    key       = s.group(\"key\").lower()\n",
        "    location  = locations[s.group(\"location\")]\n",
        "\n",
        "    # If the special keys were pressed with the others, then just add as a tag\n",
        "    if key in [\"shift\", \"control\", \"alt\", \"meta\"] and last_event == \"keypress\":\n",
        "      keys_pressed[-1][-1] = special_keys[key]\n",
        "      continue \n",
        "\n",
        "    last_event = event\n",
        "\n",
        "    if event == \"keypress\":\n",
        "      # Timestamp, key side, key      \n",
        "      keys_pressed.append([timestamp, keys_mapped.get(key, 19), location, 0]) # Last is for special keys\n",
        "    elif event == \"keyup\" and key not in [\"shift\", \"meta\", \"control\", \"alt\", \"backspace\", \"arrowleft\", \"arrowright\"]:\n",
        "      # For now ignore these, figuring out what to do with them is a later problem\n",
        "      keys_released.append([timestamp, keys_mapped.get(key, 19), location, 0])\n",
        "  all_keys_pressed[index] = keys_pressed\n",
        "  all_keys_released[index] = keys_released\n",
        "\n",
        "# We would like to start measuring from when our first key is let go \n",
        "# Because that is how we measure sequences\n",
        "\n",
        "keys_pressed = []\n",
        "keys_released = []\n",
        "\n",
        "for index in all_keys_pressed.keys():\n",
        "  kp = all_keys_pressed[index]\n",
        "  keys_pressed.extend(kp[1:])\n",
        "\n",
        "\n",
        "for index in all_keys_released.keys():\n",
        "  kr = all_keys_released[index]\n",
        "  keys_released.extend(kr[0:-1])\n",
        "\n",
        "print(len(keys_pressed))\n",
        "print(len(keys_released))"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5680\n",
            "5680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNSJCRNpFarQ",
        "colab_type": "text"
      },
      "source": [
        "Go through all our data and split up the watch data by the timestamp from the keyboard log. \n",
        "\n",
        "Each sequence begins when the first key is lifted, and ends when the next key is pressed. \n",
        "\n",
        "Map each sequence to a key."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyW1D_IJbWQx",
        "colab_type": "code",
        "outputId": "ea20ca0a-2fac-474d-8806-2657cd7c6150",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "sequences = []\n",
        "predictions = []\n",
        "\n",
        "copy_acc = watch_acc\n",
        "\n",
        "for i in range(len(keys_pressed)):\n",
        "\n",
        "  start = int(keys_released[i][0])\n",
        "  end = int(keys_pressed[i][0])\n",
        "\n",
        "  key = keys_pressed[i][1]\n",
        "  loc = keys_pressed[i][2] #Ignore for now \n",
        "\n",
        "  sequence = []\n",
        "\n",
        "  while len(copy_acc) != 0:\n",
        "    # We want to remove the line so we dont have to iterate trough everything again\n",
        "    line = copy_acc.pop(0)\n",
        "    if line == ['']:\n",
        "      continue \n",
        "\n",
        "    time, acc_x, acc_y, acc_z = line[0], line[1], line[2], line[3]\n",
        "\n",
        "    current_time = int(time)\n",
        "\n",
        "    if current_time < start:\n",
        "      continue \n",
        "    if current_time >= end:\n",
        "      break \n",
        "\n",
        "    sequence.append([float(acc_x), float(acc_y), float(acc_z)])\n",
        "  predictions.append(key)\n",
        "  sequences.append(sequence)\n",
        "\n",
        "# We want to know how much data we have\n",
        "# Should match up with how many keys_pressed we have\n",
        "print(len(sequences))\n",
        "print(len(predictions)) "
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5680\n",
            "5680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nXBa3GHpJig",
        "colab_type": "text"
      },
      "source": [
        "Now we pad the shorter sequences with [0, 0, 0] to match the length of the longest sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emIM0-N4pQh3",
        "colab_type": "code",
        "outputId": "e49ee807-0cce-411b-de8c-15641e57b037",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "max_seq_3 = max(sequences,key=len)\n",
        "max_len = len(max_seq_3)\n",
        "print(max_len)\n",
        "\n",
        "padded_sequences = []\n",
        "for sequence in sequences:\n",
        "  while len(sequence) < max_len:\n",
        "     sequence.append([0, 0, 0])\n",
        "  np.stack(sequence)\n",
        "  padded_sequences.append(sequence)\n",
        "np_sequences = np.stack(padded_sequences)\n",
        "\n",
        "print(np_sequences.shape)"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "270\n",
            "(5680, 270, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogCwlcxjsLKP",
        "colab_type": "text"
      },
      "source": [
        "Now we make our classifier\n",
        "\n",
        "It should take in a vector thats **N * M * 3**\n",
        "\n",
        "Where N = Number of squences and M = Sequence length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcDOAth0sS1_",
        "colab_type": "code",
        "outputId": "e20e0ed5-d22a-4be6-abc0-92f2e3a2e78e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Our shape is (5680, 270, 3)\n",
        "\n",
        "# So sklearn expects 2d arrays... gotta reshape\n",
        "N, nx, ny = np_sequences.shape\n",
        "new_sequences = np_sequences.reshape((N,nx*ny))\n",
        "\n",
        "# Split into train, validation, and test sets\n",
        "# I will do about 70 train and 30 test\n",
        "train_data, test_data = new_sequences[:3976,:], new_sequences[3976:,:]\n",
        "print (train_data.shape)\n",
        "print (test_data.shape)\n",
        "train_ts, test_ts = predictions[:3976], predictions[3976:]\n",
        "\n",
        "# Create Classifier\n",
        "rfc=RandomForestClassifier(n_estimators=150, max_features=0.15, min_samples_leaf=60, oob_score=True)\n",
        "\n",
        "# Train the model using the training set\n",
        "rfc.fit(train_data,train_ts)\n",
        "\n",
        "# Test our accuracy\n",
        "test_ys=rfc.predict(test_data)\n",
        "\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(test_ts, test_ys))\n",
        "# Key Prediction =~ 23% accuracy\n",
        "\n",
        "# Store Model\n",
        "import joblib\n",
        "\n",
        "filename = \"/content/gdrive/My Drive/School Winter 2020/Csc490/data/weights.joblib\"\n",
        "weights = joblib.dump(rfc,filename)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3976, 810)\n",
            "(1704, 810)\n",
            "Accuracy: 0.24178403755868544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKVY-hRZgcNR",
        "colab_type": "text"
      },
      "source": [
        "This is to just to show that our model is bad at predicting... because of all the space predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lMdq8P0I3bn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for y, t in zip(test_ys, test_ts):\n",
        "  if y!= t:\n",
        "    print(y, t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1hb0T-uOY14",
        "colab_type": "text"
      },
      "source": [
        "Ok let's try a different model - rnn sequential, \n",
        "\n",
        "Just to compare accuracy\n",
        "\n",
        "First we will have to convert the predictions into their numerical form"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WEB6ZoxOYDC",
        "colab_type": "code",
        "outputId": "ee0f24f2-9462-4619-e5de-f9685fffbdef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "uniq_pred = np.unique(predictions)\n",
        "print(uniq_pred)\n",
        "num_uniq = uniq_pred.shape[0]\n",
        "\n",
        "pred_numbered = []\n",
        "for key in predictions:\n",
        "  pred_numbered.append(list(uniq_pred).index(key))\n",
        "\n",
        "uniq_pred2 = np.unique(pred_numbered)\n",
        "num_uniq2 = uniq_pred2.shape[0]\n",
        "\n",
        "print(uniq_pred, num_uniq)\n",
        "print(uniq_pred2, num_uniq2)\n",
        "\n",
        "def make_onehot(indicies, total=250):\n",
        "    \"\"\"\n",
        "    Convert indicies into one-hot vectors by\n",
        "        1. Creating an identity matrix of shape [total, total]\n",
        "        2. Indexing the appropriate columns of that identity matrix\n",
        "    \"\"\"\n",
        "    I = np.eye(total)\n",
        "    return I[indicies]\n",
        "\n",
        "hot_predictions = make_onehot(pred_numbered, num_uniq2)\n",
        "print (hot_predictions[:5])"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 19]\n",
            "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 19] 18\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17] 18\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qixR7kIFhGlv",
        "colab_type": "text"
      },
      "source": [
        "This function broke at some point, and I cant be bothered to fix it :("
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi7x8OwebWQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Split into train, validation, and test sets\n",
        "# I will do about 60 train, 20 valid and 20 test\n",
        "\n",
        "N, nx, ny = np_sequences.shape\n",
        "print(N, nx, ny)\n",
        "new_sequences = np_sequences.reshape((N,nx*ny))\n",
        "\n",
        "train_data, valid_data, test_data = new_sequences[:3408‬,:],  new_sequences[3408‬:4544,:], new_sequences[4544:,:]\n",
        "print (train_data.shape)\n",
        "print (valid_data.shape)\n",
        "print (test_data.shape)\n",
        "train_ts, valid_ts, test_ts = hot_predictions[:3408‬],  hot_predictions[3408‬:4544], hot_predictions[4544:]\n",
        "\n",
        "dim = nx*ny\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(N, activation='relu', input_dim=dim))\n",
        "#model.add(Dense(N, activation='relu'))\n",
        "model.add(Dense(3, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_data, train_ts,\n",
        "          batch_size=64, epochs=10,\n",
        "          validation_data=(valid_data, valid_ts))\n",
        "\n",
        "\n",
        "score = model.evaluate(test_data, test_ts, batch_size=64)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2Dmpr10g8S0",
        "colab_type": "text"
      },
      "source": [
        "Finally this is what the prediction function should look like (in flask)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jILzt7GMaNQh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "12090d0b-089f-4e3a-c5c2-d3d058fc184d"
      },
      "source": [
        "def predict(batch_of_10, ts):\n",
        "  path = \"/content/gdrive/My Drive/School Winter 2020/Csc490/data/weights.joblib\"\n",
        "  model = joblib.load(path)\n",
        "  acc = model.score(batch_of_10, ts)\n",
        "  if acc >= 0.2:\n",
        "    return True\n",
        "  return False  \n",
        "\n",
        "batch_of_10 = new_sequences[:10]\n",
        "ts = predictions[:10]\n",
        "predict(batch_of_10, ts)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    }
  ]
}